{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4378d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMEN 415 | Group 2 | Huzefa Ansari, Amina Saleh, Jenny Hua, Lauren Wentzel | Winter 2023 \n",
    "# Final project | Image Classification Dataset\n",
    "\n",
    "# Import Programs\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Import Modules from Keras to Facilitate Modeling\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img,img_to_array\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout,Input, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32b21f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Sort Through Training Data\n",
    "\n",
    "def sortTrainingData():\n",
    "    normalData = trainingFolder/\"NORMAL\" # Specify data with Normal Patients\n",
    "    pneumoniaData = trainingFolder/\"PNEUMONIA\" # Specify data obtained from Patients with Pneumonia\n",
    "    normalImages = normalData.glob(\"*.jpeg\")  # # Locate all image files in the Normal Subsection\n",
    "    pneumoniaImages = pneumoniaData.glob(\"*.jpeg\") # Locate all image files in the Pneumonia Subsection\n",
    "    trainingData = [] # Create data Array\n",
    "    trainingLabels = [] # Create label Array\n",
    "    for img in normalImages: # If data is normal, append the word 'NORMAL' to the corresponding image indices\n",
    "        trainingData.append(img)\n",
    "        trainingLabels.append(\"NORMAL\") \n",
    "    for img in pneumoniaImages: # If pneumonia data, append the word 'PNEUMONIA' to the corresponding image indices\n",
    "        trainingData.append(img)\n",
    "        trainingLabels.append(\"PNEUMONIA\")\n",
    "    data = pd.DataFrame(trainingData) # Reshape the training data images\n",
    "    data.columns = [\"images\"] # Assign the columns as the images from the training dataset\n",
    "    data[\"labels\"] = trainingLabels # Assign labels to ensure each image is associated to the corresponding label\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8f46d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to sift through Testing Data\n",
    "\n",
    "def sortTestingData(isVal = True):\n",
    "    normalData = testingFolder/\"NORMAL\" # Specify data with Normal Patients\n",
    "    pneumoniaData = testingFolder/\"PNEUMONIA\"  # Specify data obtained from Patients with Pneumonia\n",
    "    normalImages = normalData.glob(\"*.jpeg\") # Locate all image files in the Normal Subsection\n",
    "    pneumoniaImages = pneumoniaData.glob(\"*.jpeg\") # Locate all image files in the Pneumonia Subsection\n",
    "    data = [] # Create Data array\n",
    "    labels = [] # Create Label Array\n",
    "    def prepare(case): # Prepare the data in regards to shape, image and size\n",
    "        for img in case:\n",
    "            img = cv2.imread(str(img)) # Read the Image as a String\n",
    "            img = cv2.resize(img, (224, 224)) # Resize the image to 224x224\n",
    "            if img.shape[2] == 1:\n",
    "                img = np.dstack([img, img, img])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Identify the colors within the image\n",
    "            img = img.astype(np.float32)/255.\n",
    "            if case == normalImages:\n",
    "                label = to_categorical(0, num_classes=2) # If image is deemed 'normal', assign it to category 1: normal\n",
    "            else:\n",
    "                label = to_categorical(1, num_classes=2) # If image is deemed 'pneumonia', assign it to category 1: pneumonia\n",
    "            data.append(img) # Append Images to one Array\n",
    "            labels.append(label) # Append Labels to one Array\n",
    "        return data, labels\n",
    "    prepare(normalImages) \n",
    "    testData, testLabels = prepare(pneumoniaImages) \n",
    "    test_Data = np.array(testData) # Shape/quanitfy the data to one array\n",
    "    test_Labels = np.array(testLabels) # Shape/quantify the labels to one array \n",
    "    return test_Data, test_Labels # Return Images and Data as seperate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ad70503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curate the Data for use in the Model \n",
    "    \n",
    "def dataCuration(data, batchSize): \n",
    "    n = len(data)\n",
    "    numberOfBatches = n//batchSize # Identify the number of batches based on the number provided to the function\n",
    "    \n",
    "    batchData = np.zeros((batchSize, 224, 224, 3), dtype=np.float32) # Create a sized matrix for the data per batch\n",
    "    batchLabels = np.zeros((batchSize, 2), dtype=np.float32) # Create a sized matrix for the labels per batch\n",
    "    \n",
    "    indices = np.arange(n) # Arrange the indices in ascending order\n",
    "    \n",
    "    i=0 \n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(indices) # Shuffle the indices\n",
    "        count = 0\n",
    "        nextBatch = indices[(i * batchSize):(i+1)*batchSize] # Select which batch is being curated\n",
    "        for j, idx in enumerate(nextBatch):\n",
    "            imgName = data.iloc[idx][\"images\"] # Identify the Image\n",
    "            label = data.iloc[idx][\"labels\"] # Label the Image\n",
    "            if label == \"NORMAL\": # Normal Images are Assigned an Index of 0\n",
    "                label = 0 \n",
    "            else: # Pneumonia Images are assigned an index of 1\n",
    "                label = 1\n",
    "            encodedLabel = to_categorical(label, num_classes=2) # Encode labels based on the categories assigned above\n",
    "            img = cv2.imread(str(imgName)) # Read the file\n",
    "            img = cv2.resize(img, (224, 224)) # Reshape the file\n",
    "            if img.shape[2] == 1:\n",
    "                img = np.dstack([img, img, img])\n",
    "                \n",
    "            origImage = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Analyze the color of the image\n",
    "            origImage = img.astype(np.float32)/255.\n",
    "            \n",
    "            batchData[count] = origImage # Append the image based on the counter and batch\n",
    "            batchLabels[count] = encodedLabel # Append the label based on the counter and the batcg\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if count == batchSize - 1: \n",
    "                break\n",
    "        i += 1\n",
    "        \n",
    "        yield batchData, batchLabels # Return Data and Labels for each Batch\n",
    "        \n",
    "        if i >= numberOfBatches: \n",
    "            i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abd7ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aminasaleh/BMEN 415/chest_xray\n",
      "['.DS_Store', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Locate File and Directories\n",
    "\n",
    "print (os.path.abspath(\"chest_xray\")) # Locate File\n",
    "dataFile = Path('/Users/aminasaleh/Downloads/chest_xray/') # Specify File Location\n",
    "print(os.listdir(dataDirectory)) # Find the Directories in the Files\n",
    "\n",
    "trainingFolder = dataFile/\"train\" # Identify Training Folder\n",
    "testingFolder = dataFile/\"test\" # Idenitfy Testing Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "709e8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort Data\n",
    "\n",
    "modelTraining = sortTrainingData() # Call Function to Sort the Training Data\n",
    "testData, testLabels = sortTestingData(isVal=False)  # Call Function to Sort/Shape the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "164a9013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 222, 222, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 109, 109, 32)      9248      \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 109, 109, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 54, 54, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 52, 52, 64)        18496     \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 52, 52, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 26, 26, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 43264)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2768960   \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,797,730\n",
      "Trainable params: 2,797,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Establish the Sequential model from Keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Summarize the Model Parameters\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23b44496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "326/326 [==============================] - 158s 481ms/step - loss: 0.2124 - accuracy: 0.8733\n",
      "Epoch 2/3\n",
      "326/326 [==============================] - 163s 499ms/step - loss: 0.0994 - accuracy: 0.9195\n",
      "Epoch 3/3\n",
      "326/326 [==============================] - 176s 539ms/step - loss: 0.0602 - accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "# Train the Dataset Based on the Data\n",
    "\n",
    "batchSize = 16 # Specify the batch Size\n",
    "numberOfEpochs = 3 # Specify the number of Epochs\n",
    "curatedTrainingData = dataCuration(trainData, batchSize) # Curate the training Data based on Batch Size\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) # Compile the Model\n",
    "\n",
    "modelFit = model.fit(curatedTrainingData, epochs=numberOfEpochs, steps_per_epoch = (trainData.shape[0]//batchSize)) # Fit the Model to the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab92c72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 5s 117ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25       234\n",
      "           1       0.66      1.00      0.80       390\n",
      "\n",
      "    accuracy                           0.68       624\n",
      "   macro avg       0.83      0.57      0.52       624\n",
      "weighted avg       0.79      0.68      0.59       624\n",
      "\n",
      "[[ 33 201]\n",
      " [  0 390]]\n",
      "The Accuracy Score for the Sequential Model is: 0.67788\n"
     ]
    }
   ],
   "source": [
    "# Predict the Outcome and Specify The Accuracy Metrics\n",
    "\n",
    "prediction = model.predict(testData, batch_size=16) # Predict the Data with the Batch Sizes and test Data\n",
    "prediction = np.argmax(prediction, axis=-1) # Predict the labels for the data above \n",
    "labels = np.argmax(testLabels, axis=-1) # Asssign the labels to an independent array\n",
    "\n",
    "#Display the Accuracy Metrics\n",
    "\n",
    "print(classification_report(labels, prediction))\n",
    "print(confusion_matrix(labels, prediction))\n",
    "print(\"The Accuracy Score for the Sequential Model is:\", round((accuracy_score(labels, prediction)),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9ce31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa12e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
